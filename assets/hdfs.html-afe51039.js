import{_ as n,Y as o,Z as i,a0 as e,a1 as a,a2 as d,a3 as s,a4 as t,E as h}from"./framework-957baa9a.js";const c={},r=e("h1",{id:"hdfs",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#hdfs","aria-hidden":"true"},"#"),a(" HDFS")],-1),p=e("p",null,"[TOC]",-1),_=e("p",null,"Hadoop 分布式文件系统(HDFS)",-1),m=e("p",null,"分布式文件系统应用场景: 数据集超过单台计算机的存储能力, 分区跨计算机存储, 势必引入网络编程的复杂性",-1),u=e("p",null,"同时, Hadoop也集成了其他文件系统, 比如本地文件系统和Amazon S3",-1),f=e("h2",{id:"_1-hdfs设计",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_1-hdfs设计","aria-hidden":"true"},"#"),a(" 1. HDFS设计")],-1),b=e("li",null,[a("流式数据访问 "),e("ol",null,[e("li",null,"hdfs的构建思路是: 一次写入, 多次读取, 长时间在数据集上进行各种分析, 每次要用到大部分或者全部数据."),e("li",null,"读取整个数据集的耗时比读取第一条的耗时更重要")])],-1),k=e("li",null,"商用硬件: 因为部署在庞大的计算机集群上, 节点故障记录还是非常高的, HDFS设计成遇到故障继续运行, 不让用户察觉",-1),S=e("li",null,"大量小文件: namenode将文件系统元数据保存在内存中, 首先内存的大小(一百万文件, 至少需要300M的内存)",-1),H=e("li",null,"HDFS只能有一个writer, 写操作总是将数据添加到末尾",-1),v=t(`<h2 id="_2-概念" tabindex="-1"><a class="header-anchor" href="#_2-概念" aria-hidden="true">#</a> 2. 概念</h2><ol><li><p>数据块</p><ol><li>文件系统块通常是硬盘块的整数倍</li><li>HDFS的默认块(block)是64MB, HDFS上的文件被划分为块(block)大小的多个分块(chunk), 但是小于block的文件不会占据整个块的空间</li><li>设置大的block, 是为了最小化寻址开销, 如果设置的块足够大, 从磁盘传输数据的时间会明显大于定位文件的时间, 因而传输一个由多个块组成的文件取决于磁盘的传输效率 <ol><li>如果寻址耗时10ms, 传输速率100MB/s, 要想寻址仅占传输的1%, 则需要设置块的大小为100MB, 实际上默认是64MB, 很多情况下使用128MB的设置</li><li>但是块不能设置的过大, MapReduce中的map任务一次只处理一个块中的数据, 如果任务数太少(少于集群中的节点数)则会运行太慢)</li></ol></li><li>对块抽象 <ol><li><p>可以让一个文件大于网络中任意磁盘的容量, 存储在多个磁盘中</p></li><li><p>简化存储子系统设计, 块只存储数据的一部分, 元数据(权限信息等)由其他系统管理</p></li><li><p>数据容错能力和可用性, 将块数据复制到几个独立的机器上(默认为3个), 如果一个块不可用, 可以从别处读取副本, 并修复丢失的块. 也可以提高块的复本数量, 分散集群中的读取负载</p></li><li><p>查看各个文件由哪些块构成</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>hadoop <span class="token function">fsck</span> / <span class="token parameter variable">-files</span> <span class="token parameter variable">-blocks</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div></li></ol></li></ol></li><li><p>namenode和datanode</p><ul><li>HDFS集群有两类节点以管理者(namenode)-工作者(datanode)模式运行, namenode管理文件系统的命名空间, 维护文件系统树及整棵树内所有的文件和目录(命名空间镜像文件和编辑日志文件), 但不保留块的位置信息, 因为这些信息会在系统启动时由datanode(数据节点)重建.</li><li>客户端代表用户与namenode和datanode交互来访问整个文件系统, 因为提供了POSIX(可移植操作系统界面), 无需知道namenode和datanode, 用户也能实现功能</li><li>datanode是文件系统的工作节点, 根据需要存储和检索数据块(受客户端或namenode调度), 并定期向namenode发送它们所存储的块的列表.</li><li>没有namenode将无法使用文件系统, 容错机制: hadoop可以通过配置在多个文件系统上是namenode持久化, 通常是写入本地磁盘的同时, 写入一个NFS, 或者运行一个辅助namenode, 持续备份namenode(这个是定时备份, 并不是完全同步, 有可能丢失数据)</li></ul></li><li><p>联邦HDFS 支持多个namenode, 每个负责独立的命名空间卷, 互补相同, 比如/user /share</p></li><li><p>HDFS的高可用 对于大型集群, namenode冷启动需要30分钟甚至更长, 如果namenode失效, 恢复会影响系统的持续使用, 也会影响到日常维护 办法: 配置一对活动-备用(active-standby)namenode, 当活动namenode失效, 备用接管</p><ul><li>需要高可用的共享存储实现编辑日志的共享, 如果备用namenode接管, 将通读共享编辑日志, 实现状态同步, 并继续读取活动namenode写入的新条目</li><li>datanode需要同时向两个namenode发送数据块处理报告</li><li>客户端需要使用特定机制来处理namenode的失效</li></ul></li></ol><h2 id="_3-命令行接口" tabindex="-1"><a class="header-anchor" href="#_3-命令行接口" aria-hidden="true">#</a> 3. 命令行接口</h2><ol><li>hadoop fs -copyFromLocal local_path hdfs_path</li><li>hadoop fs -copyToLocal hdfs_path local_path</li><li>hadoop fs -mkdir dirs</li><li>hadoop fs -ls</li></ol>`,4);function F(x,D){const l=h("RouterLink");return o(),i("div",null,[r,p,_,m,u,f,e("ol",null,[b,k,e("li",null,[a("适用高数据吞吐量应用, 不适用低延迟访问(低延迟访问考虑"),d(l,{to:"/bigdata/hbase.html"},{default:s(()=>[a("Hbase")]),_:1}),a(")")]),S,H]),v])}const M=n(c,[["render",F],["__file","hdfs.html.vue"]]);export{M as default};
