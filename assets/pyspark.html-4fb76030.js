import{_ as l,Y as i,Z as c,a0 as a,a1 as e,a2 as t,a3 as n,E as s}from"./framework-957baa9a.js";const h={},d=a("h1",{id:"pyspark",tabindex:"-1"},[a("a",{class:"header-anchor",href:"#pyspark","aria-hidden":"true"},"#"),e(" Pyspark")],-1),u=a("h2",{id:"basic",tabindex:"-1"},[a("a",{class:"header-anchor",href:"#basic","aria-hidden":"true"},"#"),e(" Basic")],-1),p={href:"https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-glue-data-catalog-hive.html",target:"_blank",rel:"noopener noreferrer"},_=a("blockquote",null,[a("p",null,"The AWS Glue Data Catalog is an Apache Hive metastore-compatible catalog. You can configure your AWS Glue jobs and development endpoints to use the Data Catalog as an external Apache Hive metastore. You can then directly run Apache Spark SQL queries against the tables stored in the Data Catalog. AWS Glue dynamic frames integrate with the Data Catalog by default. However, with this feature, Spark SQL jobs can start using the Data Catalog as an external Hive metastore.")],-1),m=a("h2",{id:"常见问题索引",tabindex:"-1"},[a("a",{class:"header-anchor",href:"#常见问题索引","aria-hidden":"true"},"#"),e(" 常见问题索引")],-1);function g(f,k){const r=s("ExternalLinkIcon"),o=s("RouterLink");return i(),c("div",null,[d,u,a("ol",null,[a("li",null,[a("a",p,[e("Spark SQL 与 AWS Glue"),t(r)]),_])]),m,a("ol",null,[a("li",null,[t(o,{to:"/bigdata/mysql_to_s3.html"},{default:n(()=>[e("记录mysql迁移aws")]),_:1})]),a("li",null,[t(o,{to:"/bigdata/schema.html"},{default:n(()=>[e("pyspark.sql.types.StructType 序列化")]),_:1})])])])}const y=l(h,[["render",g],["__file","pyspark.html.vue"]]);export{y as default};
